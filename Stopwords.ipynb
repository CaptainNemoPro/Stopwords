{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d388adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9318997",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('articles are words that define a noun as specific or unspecific. Consider the following examples: By using the article the, we’ve shown that it was one specific day that was long and one specific cup of tea that tasted good. By using the article a, we’ve created a general statement, implying that any cup of tea would')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc4dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54280c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3036ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles\n",
      "words\n",
      "define\n",
      "noun\n",
      "specific\n",
      "unspecific\n",
      ".\n",
      "Consider\n",
      "following\n",
      "examples\n",
      ":\n",
      "By\n",
      "using\n",
      "article\n",
      ",\n",
      "’\n",
      "shown\n",
      "one\n",
      "specific\n",
      "day\n",
      "long\n",
      "one\n",
      "specific\n",
      "cup\n",
      "tea\n",
      "tasted\n",
      "good\n",
      ".\n",
      "By\n",
      "using\n",
      "article\n",
      ",\n",
      "’\n",
      "created\n",
      "general\n",
      "statement\n",
      ",\n",
      "implying\n",
      "cup\n",
      "tea\n",
      "would\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    if i in stop_words:\n",
    "        pass\n",
    "    else: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9200a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stop_words(x):\n",
    " y=nltk.word_tokenize(x)\n",
    " for i in y:\n",
    "    if i in stopwords.words(\"english\"): \n",
    "        pass\n",
    "    else: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa143453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "I\n",
      "Harshit\n",
      "Jain\n",
      "I\n",
      "data\n",
      "analyst\n"
     ]
    }
   ],
   "source": [
    "rem_stop_words(\"Hi I am Harshit Jain and I am a data analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d8a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_stop_words(x):\n",
    " y=nltk.word_tokenize(x)\n",
    " my_list=[]\n",
    " for i in y:\n",
    "    if i in stopwords.words(\"english\"): \n",
    "        pass\n",
    "    else:\n",
    "        my_list.append(i)\n",
    "        return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61888a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
